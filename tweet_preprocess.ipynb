{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78YgDdEsAVKS",
        "outputId": "e3a2ff6e-3c3b-4c00-c6cc-b2ac31a06dbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load tweet data from JSON file\n",
        "with open('cleaned_data.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Initialize sentiment analysis and topic classification pipelines with GPU support\n",
        "sentiment_classifier = pipeline(\"sentiment-analysis\", device=0)\n",
        "topic_classifier = pipeline(\"zero-shot-classification\", device=0)\n",
        "\n",
        "# Define topics for zero-shot classification\n",
        "topics = [\"politics\", \"education\", \"technology\", \"sports\", \"entertainment\"]\n",
        "\n",
        "# Generate sentiment and topic labels for each tweet\n",
        "labeled_tweets = []\n",
        "total_tweets = len(data)\n",
        "for i, item in enumerate(data, start=1):\n",
        "    tweet = item.get('text', '')\n",
        "    if tweet:\n",
        "        try:\n",
        "            # Sentiment Analysis\n",
        "            sentiment_result = sentiment_classifier(tweet)[0]\n",
        "            sentiment_label = \"__label_sentiment__\" + sentiment_result['label'].lower()\n",
        "\n",
        "            # Topic Classification (zero-shot classification)\n",
        "            topic_result = topic_classifier(tweet, topics)\n",
        "            topic_label = \"__label_topic__\" + topic_result['labels'][0].lower()  # Select the most likely topic\n",
        "\n",
        "            # Combine labels with tweet content\n",
        "            labeled_tweet = f\"{sentiment_label} {topic_label} {tweet.strip()}\"\n",
        "            labeled_tweets.append(labeled_tweet)\n",
        "\n",
        "            # Progress update every 100 tweets\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Processed {i}/{total_tweets} tweets ({(i / total_tweets) * 100:.2f}% complete)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing tweet: {tweet}\\nError: {e}\")\n",
        "\n",
        "# Save labeled tweets to a new file\n",
        "with open('labeled_tweets.txt', 'w') as file:\n",
        "    for labeled_tweet in labeled_tweets:\n",
        "        file.write(labeled_tweet + \"\\n\")\n",
        "\n",
        "print(\"Labeled tweets saved to labeled_tweets.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCihkTT6DR7Z",
        "outputId": "c76485f1-b9af-454e-fe06-020ae248bd50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100/10000 tweets (1.00% complete)\n",
            "Processed 200/10000 tweets (2.00% complete)\n",
            "Processed 300/10000 tweets (3.00% complete)\n",
            "Processed 400/10000 tweets (4.00% complete)\n",
            "Processed 500/10000 tweets (5.00% complete)\n",
            "Processed 600/10000 tweets (6.00% complete)\n",
            "Processed 700/10000 tweets (7.00% complete)\n",
            "Processed 800/10000 tweets (8.00% complete)\n",
            "Processed 900/10000 tweets (9.00% complete)\n",
            "Processed 1000/10000 tweets (10.00% complete)\n",
            "Processed 1100/10000 tweets (11.00% complete)\n",
            "Processed 1200/10000 tweets (12.00% complete)\n",
            "Processed 1300/10000 tweets (13.00% complete)\n",
            "Processed 1400/10000 tweets (14.00% complete)\n",
            "Processed 1500/10000 tweets (15.00% complete)\n",
            "Processed 1600/10000 tweets (16.00% complete)\n",
            "Processed 1700/10000 tweets (17.00% complete)\n",
            "Processed 1800/10000 tweets (18.00% complete)\n",
            "Processed 1900/10000 tweets (19.00% complete)\n",
            "Processed 2000/10000 tweets (20.00% complete)\n",
            "Processed 2100/10000 tweets (21.00% complete)\n",
            "Processed 2200/10000 tweets (22.00% complete)\n",
            "Processed 2300/10000 tweets (23.00% complete)\n",
            "Processed 2400/10000 tweets (24.00% complete)\n",
            "Processed 2500/10000 tweets (25.00% complete)\n",
            "Processed 2600/10000 tweets (26.00% complete)\n",
            "Processed 2700/10000 tweets (27.00% complete)\n",
            "Processed 2800/10000 tweets (28.00% complete)\n",
            "Processed 2900/10000 tweets (29.00% complete)\n",
            "Processed 3000/10000 tweets (30.00% complete)\n",
            "Processed 3100/10000 tweets (31.00% complete)\n",
            "Processed 3200/10000 tweets (32.00% complete)\n",
            "Processed 3300/10000 tweets (33.00% complete)\n",
            "Processed 3400/10000 tweets (34.00% complete)\n",
            "Processed 3500/10000 tweets (35.00% complete)\n",
            "Processed 3600/10000 tweets (36.00% complete)\n",
            "Processed 3700/10000 tweets (37.00% complete)\n",
            "Processed 3800/10000 tweets (38.00% complete)\n",
            "Processed 3900/10000 tweets (39.00% complete)\n",
            "Processed 4000/10000 tweets (40.00% complete)\n",
            "Processed 4100/10000 tweets (41.00% complete)\n",
            "Processed 4200/10000 tweets (42.00% complete)\n",
            "Processed 4300/10000 tweets (43.00% complete)\n",
            "Processed 4400/10000 tweets (44.00% complete)\n",
            "Processed 4500/10000 tweets (45.00% complete)\n",
            "Processed 4600/10000 tweets (46.00% complete)\n",
            "Processed 4700/10000 tweets (47.00% complete)\n",
            "Processed 4800/10000 tweets (48.00% complete)\n",
            "Processed 4900/10000 tweets (49.00% complete)\n",
            "Processed 5000/10000 tweets (50.00% complete)\n",
            "Processed 5100/10000 tweets (51.00% complete)\n",
            "Processed 5200/10000 tweets (52.00% complete)\n",
            "Processed 5300/10000 tweets (53.00% complete)\n",
            "Processed 5400/10000 tweets (54.00% complete)\n",
            "Processed 5500/10000 tweets (55.00% complete)\n",
            "Processed 5600/10000 tweets (56.00% complete)\n",
            "Processed 5700/10000 tweets (57.00% complete)\n",
            "Processed 5800/10000 tweets (58.00% complete)\n",
            "Processed 5900/10000 tweets (59.00% complete)\n",
            "Processed 6000/10000 tweets (60.00% complete)\n",
            "Processed 6100/10000 tweets (61.00% complete)\n",
            "Processed 6200/10000 tweets (62.00% complete)\n",
            "Processed 6300/10000 tweets (63.00% complete)\n",
            "Processed 6400/10000 tweets (64.00% complete)\n",
            "Processed 6500/10000 tweets (65.00% complete)\n",
            "Processed 6600/10000 tweets (66.00% complete)\n",
            "Processed 6700/10000 tweets (67.00% complete)\n",
            "Processed 6800/10000 tweets (68.00% complete)\n",
            "Processed 6900/10000 tweets (69.00% complete)\n",
            "Processed 7000/10000 tweets (70.00% complete)\n",
            "Processed 7100/10000 tweets (71.00% complete)\n",
            "Processed 7200/10000 tweets (72.00% complete)\n",
            "Processed 7300/10000 tweets (73.00% complete)\n",
            "Processed 7400/10000 tweets (74.00% complete)\n",
            "Processed 7500/10000 tweets (75.00% complete)\n",
            "Processed 7600/10000 tweets (76.00% complete)\n",
            "Processed 7700/10000 tweets (77.00% complete)\n",
            "Processed 7800/10000 tweets (78.00% complete)\n",
            "Processed 7900/10000 tweets (79.00% complete)\n",
            "Processed 8000/10000 tweets (80.00% complete)\n",
            "Processed 8100/10000 tweets (81.00% complete)\n",
            "Processed 8200/10000 tweets (82.00% complete)\n",
            "Processed 8300/10000 tweets (83.00% complete)\n",
            "Processed 8400/10000 tweets (84.00% complete)\n",
            "Processed 8500/10000 tweets (85.00% complete)\n",
            "Processed 8600/10000 tweets (86.00% complete)\n",
            "Processed 8700/10000 tweets (87.00% complete)\n",
            "Processed 8800/10000 tweets (88.00% complete)\n",
            "Processed 8900/10000 tweets (89.00% complete)\n",
            "Processed 9000/10000 tweets (90.00% complete)\n",
            "Processed 9100/10000 tweets (91.00% complete)\n",
            "Processed 9200/10000 tweets (92.00% complete)\n",
            "Processed 9300/10000 tweets (93.00% complete)\n",
            "Processed 9400/10000 tweets (94.00% complete)\n",
            "Processed 9500/10000 tweets (95.00% complete)\n",
            "Processed 9600/10000 tweets (96.00% complete)\n",
            "Processed 9700/10000 tweets (97.00% complete)\n",
            "Processed 9800/10000 tweets (98.00% complete)\n",
            "Processed 9900/10000 tweets (99.00% complete)\n",
            "Processed 10000/10000 tweets (100.00% complete)\n",
            "Labeled tweets saved to labeled_tweets.txt\n"
          ]
        }
      ]
    }
  ]
}