{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of abstracts: 15000\n"]}],"source":["# Open and read the file\n","with open(\"C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\dataset.txt\", \"r\") as file:\n","    lines = file.readlines()\n","\n","# Count lines that start with unique abstract identifiers (assuming they start with ###)\n","abstract_count = sum(1 for line in lines if line.startswith(\"###\"))\n","\n","print(f\"Number of abstracts: {abstract_count}\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data has been successfully formatted for fastText.\n"]}],"source":["import re\n","\n","# Open the original dataset\n","with open(\"C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\dataset.txt\", \"r\") as file:\n","    lines = file.readlines()\n","    \n","# Initialize variables\n","data = []\n","current_abstract = []\n","current_label = None\n","\n","# Process each line to extract labeled sections\n","for line in lines:\n","    if line.startswith(\"###\"):  # New abstract identifier\n","        # Save the current abstract if there is one\n","        if current_abstract:\n","            data.append(' '.join(current_abstract))\n","            current_abstract = []  # Reset for new abstract\n","        current_label = None  # Reset label for a new abstract\n","    elif line.strip():  # Non-empty line\n","        # Match labels like BACKGROUND, METHODS, etc.\n","        match = re.match(r'^(BACKGROUND|OBJECTIVE|METHODS|RESULTS|CONCLUSIONS)\\t', line)\n","        if match:\n","            # Set the label and start a new section\n","            current_label = match.group(1).lower()\n","            # Add the new line with the fastText label format\n","            data.append(f\"__label__{current_label} {line.strip().split('\\t', 1)[-1]}\")\n","        elif current_label:\n","            # Continue appending lines within the same section\n","            data[-1] += ' '+ line.strip()\n","\n","# Save the preprocessed data in fastText format\n","with open('C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\New_Dataset.txt', 'w') as output_file:\n","    for entry in data:\n","        output_file.write(entry + '\\n')\n","\n","\n","print(\"Data has been successfully formatted for fastText.\")\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset has been successfully split into 'train.txt' and 'test.txt'.\n"]}],"source":["\n","\n","import random\n","\n","# Load the cleaned dataset\n","with open(\"C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\New_Dataset.txt\", \"r\") as file:\n","    lines = file.readlines()\n","\n","# Shuffle the dataset to ensure randomness\n","random.seed(42)  # Set a seed for reproducibility\n","random.shuffle(lines)\n","\n","# Define the split ratio\n","split_index = int(0.8 * len(lines))\n","\n","# Split the data\n","train_lines = lines[:split_index]\n","test_lines = lines[split_index:]\n","\n","# Save the train and test sets\n","with open(\"C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\train.txt\", \"w\") as train_file:\n","    train_file.writelines(train_lines)\n","\n","with open(\"C:\\\\Users\\\\asola\\\\OneDrive\\\\Desktop\\\\data science\\\\test.txt\", \"w\") as test_file:\n","    test_file.writelines(test_lines)\n","\n","print(\"Dataset has been successfully split into 'train.txt' and 'test.txt'.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":2}
