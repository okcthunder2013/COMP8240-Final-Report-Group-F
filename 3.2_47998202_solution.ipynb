{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Installation Guide for GitHub Codespaces\n",
    "\n",
    "This guide provides step-by-step instructions to install FastText in GitHub Codespaces, preparing the environment for text classification tasks.\n",
    "\n",
    "## Step 1: Update Packages and Install Dependencies\n",
    "\n",
    "First, update your packages and install the necessary dependencies for building FastText:\n",
    "\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y build-essential cmake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Clone the FastText Repository\n",
    "```bash\n",
    "git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Navigate to the FastText Directory\n",
    "```bash\n",
    "cd fastText\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and Preparing the IMDB Movie Dataset\n",
    "\n",
    "In this section, we’ll download the IMDB movie review dataset and prepare it for FastText. FastText requires a specific format for labeled data, so we’ll convert it accordingly.\n",
    "\n",
    "## Step 1: Download the IMDB Dataset\n",
    "\n",
    "1. Go to the [IMDB Movie dataset on Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n",
    "2. Download the dataset file (`IMDB Dataset.csv`) and upload it to your working directory in GitHub Codespaces.\n",
    "\n",
    "## Step 2: Prepare the Data for FastText\n",
    "\n",
    "FastText requires each line of data to follow this format:\n",
    "\n",
    "```bash\n",
    "label<label> <review text>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "```bash\n",
    "__label__positive The movie was fantastic! \n",
    "__label__negative Not worth watching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Convert IMDB Dataset to FastText Format\n",
    "\n",
    "Run the following Python script to convert the IMDB dataset into the required format. This will create `train.txt` (80% of the data) for training and `test.txt` (20%) for validation.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Preprocess and save in FastText format\n",
    "df['review'] = df['review'].str.replace('\\n', ' ').str.lower()  # Remove newlines and lowercase\n",
    "df['label'] = df['sentiment'].apply(lambda x: '__label__' + x)\n",
    "df['fasttext_format'] = df['label'] + ' ' + df['review']\n",
    "\n",
    "# Split into train and test\n",
    "df.sample(frac=0.8, random_state=42).to_csv('train.txt', columns=['fasttext_format'], index=False, header=False)\n",
    "df.drop(df.sample(frac=0.8, random_state=42).index).to_csv('test.txt', columns=['fasttext_format'], index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.txt: Contains 40,000 reviews (80% of the data) for training.\n",
    "test.txt: Contains 10,000 reviews (20% of the data) for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating the Model\n",
    "\n",
    "Training the FastText model on the prepared IMDB dataset and evaluate its performance on the test set.\n",
    "\n",
    "## Step 1: Train the Model\n",
    "\n",
    "Use the `train.txt` file to train a supervised FastText model. This command will save the trained model as `model_imdb.bin`.\n",
    "\n",
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb\n",
    "Read 9M words\n",
    "Number of words:  390624\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1487245 lr:  0.000000 avg.loss:  0.693287 ETA:  0h 0m 0s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supervised: Tells FastText to run in supervised mode, suitable for classification tasks.\n",
    "\n",
    "-input train.txt: Specifies train.txt as the training data.\n",
    "\n",
    "-output model_imdb: Sets the output file name as model_imdb.bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Evaluate the Model\n",
    "\n",
    "After training, evaluate the model on test.txt to assess its accuracy:\n",
    "\n",
    "```bash \n",
    "./fasttext test model_imdb.bin test.txt\n",
    "N       276\n",
    "P@1     0.562\n",
    "R@1     0.562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test: Tells FastText to evaluate the model on test data.\n",
    "\n",
    "model_imdb.bin: Specifies the trained model file.\n",
    "\n",
    "test.txt: Uses test.txt as the test data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test Model Predictions on Sample Sentences\n",
    "\n",
    "Positive Review Example:\n",
    "```bash\n",
    "echo \"The movie was absolutely brilliant, with stunning visuals and an amazing storyline!\" | ./fasttext predict model_imdb.bin -\n",
    "\n",
    "__label__positive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Review Example:\n",
    "```bash\n",
    "echo \"I was really disappointed by the movie; it was boring and felt too long.\" | ./fasttext predict model_imdb.bin -\n",
    "\n",
    "__label__positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above statement should have been negative but the model is not trained properley so its giving wrong output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 4: Fine-tuning the model\n",
    "\n",
    "Changing the lr (Learning Rate) reduces avg.loss\n",
    "\n",
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb -lr 0.5  \n",
    "Read 9M words\n",
    "Number of words:  350082\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1552394 lr:  0.000000 avg.loss:  0.511963 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the epochs also results in improvement\n",
    "\n",
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb -lr 0.5 -epoch 25 \n",
    "Read 9M words\n",
    "Number of words:  350082\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1574460 lr:  0.000000 avg.loss:  0.120751 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tunning results in a much better results:\n",
    "\n",
    "```bash\n",
    "./fasttext test model_imdb.bin test.txt\n",
    "N       276\n",
    "P@1     0.804\n",
    "R@1     0.804"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Using Bigrams\n",
    "***'Bigram'*** the concatenation of 2 consecutive tokens or words. Similarly we often talk about n-gram to refer to the concatenation any n consecutive tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb -lr 1 -epoch 25 -wordNgrams 2 -bucket 200000 -dim 50 \n",
    "Read 9M words\n",
    "Number of words:  350082\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1381679 lr:  0.000000 avg.loss:  0.076925 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Using Hirachichal Softmax\n",
    "\n",
    "Hierarchical softmax is a computational technique used to speed up training, especially useful for large datasets. It can be enabled by adding the ***-loss*** hs option when training the model.\n",
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb -lr 1 -epoch 25 -wordNgrams 2 -bucket 200000 -dim 50 -loss hs\n",
    "Read 9M words\n",
    "Number of words:  350082\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1455385 lr:  0.000000 avg.loss:  0.098376 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Multi-label classification\n",
    "A convenient way to handle multiple labels is to use independent binary classifiers for each label. This can be done with ***-loss*** ***one-vs-all*** or ***-loss ova***.\n",
    "```bash\n",
    "./fasttext supervised -input train.txt -output model_imdb -lr 1 -epoch 25 -wordNgrams 2 -bucket 200000 -dim 50 -loss ova\n",
    "Read 9M words\n",
    "Number of words:  350082\n",
    "Number of labels: 2\n",
    "Progress: 100.0% words/sec/thread: 1455964 lr:  0.000000 avg.loss:  0.148587 ETA:   0h 0m 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Evaluation of the model Model:\n",
    "```bash\n",
    "./fasttext test model_imdb.bin test.txt\n",
    "N       276\n",
    "P@1     0.815\n",
    "R@1     0.815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running the same sentence that the model gave Positive label instead of negative:\n",
    "```bash\n",
    "echo \"I was really disappointed by the movie; it was boring and felt too long.\" | ./fasttext predict model_imdb.bin -\n",
    "__label__negative\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
